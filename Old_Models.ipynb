{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Setup and Configuration\n",
    "# -----------------------------\n",
    "\n",
    "# Set device to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Paths\n",
    "train_csv_path = 'Train.csv'  # Path to your training CSV\n",
    "images_dir = 'datasets/dataset/images/train'  # Path to your images directory\n",
    "model_weights_path = 'custom_cnn_model.pth'  # Path to save/load your model weights\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Data Preparation\n",
    "# -----------------------------\n",
    "\n",
    "# Load train data\n",
    "train = pd.read_csv(train_csv_path)\n",
    "\n",
    "# Encode class labels into numerical format using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "train['class'] = label_encoder.fit_transform(train['class'])\n",
    "\n",
    "# Check for missing image files and filter them out\n",
    "valid_images = [img_id for img_id in train['Image_ID'] if os.path.exists(os.path.join(images_dir, img_id))]\n",
    "train = train[train['Image_ID'].isin(valid_images)].reset_index(drop=True)\n",
    "\n",
    "print(f\"Number of training samples after filtering: {len(train)}\")\n",
    "\n",
    "# Split data into training and validation sets (80% train, 20% val)\n",
    "train_df, val_df = train_test_split(\n",
    "    train, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=train['class']\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(train_df)}, Validation samples: {len(val_df)}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Dataset and DataLoader\n",
    "# -----------------------------\n",
    "\n",
    "# Define a Custom Dataset Class for Loading Images and Annotations\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, images_dir, transforms=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.images_dir = images_dir\n",
    "        self.transforms = transforms if transforms else transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_id = self.dataframe.iloc[idx]['Image_ID']\n",
    "        image_path = os.path.join(self.images_dir, image_id)\n",
    "        \n",
    "        # Load and preprocess the image\n",
    "        try:\n",
    "            image = Image.open(image_path).convert(\"RGB\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {image_path}: {e}\")\n",
    "            return None, None  # Return None if the image cannot be opened\n",
    "        \n",
    "        # Extract bounding box coordinates\n",
    "        bbox = torch.tensor(\n",
    "            [self.dataframe.iloc[idx][c] for c in ['xmin', 'ymin', 'xmax', 'ymax']], \n",
    "            dtype=torch.float32\n",
    "        )\n",
    "        \n",
    "        # Extract class label\n",
    "        label = torch.tensor(self.dataframe.iloc[idx]['class'], dtype=torch.long)\n",
    "        \n",
    "        # Apply transformations\n",
    "        if self.transforms:\n",
    "            image = self.transforms(image)\n",
    "        \n",
    "        return image, {'boxes': bbox, 'labels': label}\n",
    "\n",
    "# Define transformations for the images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),  # Resize images to 256x256\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Instantiate the training dataset and DataLoader\n",
    "train_dataset = CustomDataset(dataframe=train_df, images_dir=images_dir, transforms=transform)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=32,          # Adjust based on your GPU memory\n",
    "    shuffle=True,           # Shuffle for training\n",
    "    num_workers=4,          # Number of subprocesses for data loading\n",
    "    pin_memory=True         # Copy tensors into CUDA pinned memory\n",
    ")\n",
    "\n",
    "# Instantiate the validation dataset and DataLoader\n",
    "val_dataset = CustomDataset(dataframe=val_df, images_dir=images_dir, transforms=transform)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=32,          # Adjust based on your GPU memory\n",
    "    shuffle=False,          # No need to shuffle for evaluation\n",
    "    num_workers=4,          # Number of subprocesses for data loading\n",
    "    pin_memory=True         # Copy tensors into CUDA pinned memory\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Model Definition\n",
    "# -----------------------------\n",
    "\n",
    "# Define the CustomCNN model\n",
    "class CustomCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CustomCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.flattened_size = self._get_flattened_size()\n",
    "        self.fc1 = nn.Linear(self.flattened_size, 256)\n",
    "        self.fc2_bbox = nn.Linear(256, 4)      # Bounding box coordinates [xmin, ymin, xmax, ymax]\n",
    "        self.fc2_class = nn.Linear(256, num_classes)  # Class prediction\n",
    "\n",
    "    def _get_flattened_size(self):\n",
    "        dummy_input = torch.zeros(1, 3, 256, 256)\n",
    "        dummy_output = self._forward_conv(dummy_input)\n",
    "        return dummy_output.view(1, -1).size(1)\n",
    "\n",
    "    def _forward_conv(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self._forward_conv(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        bbox_output = self.fc2_bbox(x)\n",
    "        class_output = self.fc2_class(x)\n",
    "        return bbox_output, class_output\n",
    "\n",
    "# Define number of classes based on unique labels\n",
    "num_classes = len(train['class'].unique())\n",
    "\n",
    "# Instantiate the model and move to the correct device\n",
    "model = CustomCNN(num_classes=num_classes).to(device)\n",
    "\n",
    "# Print the model structure (optional)\n",
    "print(f\"Custom CNN Model:\\n{model}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Training Loop\n",
    "# -----------------------------\n",
    "\n",
    "# Define loss functions and optimizer\n",
    "bbox_loss_fn = nn.MSELoss()\n",
    "class_loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 3\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nStarting Epoch {epoch + 1}/{num_epochs}\")\n",
    "    model.train()\n",
    "    total_bbox_loss, total_class_loss = 0.0, 0.0\n",
    "\n",
    "    for batch_idx, (images, targets) in enumerate(tqdm(train_loader, desc=\"Training\")):\n",
    "        if images is None or targets is None:\n",
    "            print(f\"Skipping batch {batch_idx + 1} due to None values.\")\n",
    "            continue\n",
    "\n",
    "        # Move data to the correct device\n",
    "        images = images.to(device)\n",
    "        bboxes = targets['boxes'].to(device)\n",
    "        labels = targets['labels'].to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        pred_bboxes, pred_labels = model(images)\n",
    "\n",
    "        # Calculate losses\n",
    "        bbox_loss = bbox_loss_fn(pred_bboxes, bboxes)\n",
    "        class_loss = class_loss_fn(pred_labels, labels)\n",
    "        total_loss = bbox_loss + class_loss\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate losses\n",
    "        total_bbox_loss += bbox_loss.item()\n",
    "        total_class_loss += class_loss.item()\n",
    "\n",
    "    avg_bbox_loss = total_bbox_loss / len(train_loader)\n",
    "    avg_class_loss = total_class_loss / len(train_loader)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], BBox Loss: {avg_bbox_loss:.4f}, Class Loss: {avg_class_loss:.4f}')\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), model_weights_path)\n",
    "print(f\"\\nModel saved to '{model_weights_path}'\")\n",
    "\n",
    "# -----------------------------\n",
    "# 6. Evaluation Metrics\n",
    "# -----------------------------\n",
    "\n",
    "def calculate_iou(box1, box2):\n",
    "    \"\"\"\n",
    "    Calculate Intersection over Union (IoU) between two bounding boxes.\n",
    "    Boxes are in the format [xmin, ymin, xmax, ymax]\n",
    "    \"\"\"\n",
    "    x_left = max(box1[0], box2[0])\n",
    "    y_top    = max(box1[1], box2[1])\n",
    "    x_right  = min(box1[2], box2[2])\n",
    "    y_bottom = min(box1[3], box2[3])\n",
    "\n",
    "    if x_right < x_left or y_bottom < y_top:\n",
    "        return 0.0  # No overlap\n",
    "\n",
    "    intersection_area = (x_right - x_left) * (y_bottom - y_top)\n",
    "    box1_area = (box1[2]-box1[0]) * (box1[3]-box1[1])\n",
    "    box2_area = (box2[2]-box2[0]) * (box2[3]-box2[1])\n",
    "    iou = intersection_area / float(box1_area + box2_area - intersection_area)\n",
    "    return iou\n",
    "\n",
    "def evaluate_classification(model, dataloader, device):\n",
    "    \"\"\"\n",
    "    Evaluate classification performance: Accuracy, Precision, Recall, F1-Score, Confusion Matrix\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, targets in tqdm(dataloader, desc=\"Evaluating Classification\"):\n",
    "            # Handle possible None batches\n",
    "            if images is None or targets is None:\n",
    "                continue\n",
    "\n",
    "            images = images.to(device)\n",
    "            labels = targets['labels'].to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            _, preds = model(images)  # Assuming model returns (bbox, class)\n",
    "            preds = torch.argmax(preds, dim=1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        all_labels, all_preds, average='weighted', zero_division=0\n",
    "    )\n",
    "    conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "#\n",
    "    print(\"\\n--- Classification Evaluation ---\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision (Weighted): {precision:.4f}\")\n",
    "    print(f\"Recall (Weighted): {recall:.4f}\")\n",
    "    print(f\"F1-Score (Weighted): {f1:.4f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "\n",
    "def evaluate_bounding_boxes(model, dataloader, device, iou_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Evaluate bounding box predictions: Mean IoU and Precision at IoU threshold\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_iou = []\n",
    "    matched = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, targets in tqdm(dataloader, desc=\"Evaluating Bounding Boxes\"):\n",
    "            # Handle possible None batches\n",
    "            if images is None or targets is None:\n",
    "                continue\n",
    "\n",
    "            images = images.to(device)\n",
    "            true_bboxes = targets['boxes'].to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            pred_bboxes, _ = model(images)\n",
    "\n",
    "            # Move tensors to CPU for processing\n",
    "            pred_bboxes = pred_bboxes.cpu().numpy()\n",
    "            true_bboxes = true_bboxes.cpu().numpy()\n",
    "\n",
    "            # Iterate over each prediction and true box\n",
    "            for pred_box, true_box in zip(pred_bboxes, true_bboxes):\n",
    "                iou = calculate_iou(pred_box, true_box)\n",
    "                all_iou.append(iou)\n",
    "                if iou >= iou_threshold:\n",
    "                    matched += 1\n",
    "                total += 1\n",
    "\n",
    "    # Calculate metrics\n",
    "    mean_iou = np.mean(all_iou) if all_iou else 0\n",
    "    precision_at_iou = matched / total if total > 0 else 0\n",
    "\n",
    "    print(\"\\n--- Bounding Box Evaluation ---\")\n",
    "    print(f\"Mean IoU: {mean_iou:.4f}\")\n",
    "    print(f\"Precision at IoU >= {iou_threshold}: {precision_at_iou:.4f}\")\n",
    "\n",
    "def visualize_predictions(model, dataloader, device, label_encoder, num_samples=5):\n",
    "    \"\"\"\n",
    "    Visualize a few samples of ground truth and predicted bounding boxes along with class labels\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    samples_visualized = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, targets in dataloader:\n",
    "            # Handle possible None batches\n",
    "            if images is None or targets is None:\n",
    "                continue\n",
    "\n",
    "            images = images.to(device)\n",
    "            true_bboxes = targets['boxes'].to(device)\n",
    "            true_labels = targets['labels'].to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            pred_bboxes, pred_labels = model(images)\n",
    "            preds = torch.argmax(pred_labels, dim=1)\n",
    "\n",
    "            # Move tensors to CPU for visualization\n",
    "            images = images.cpu().numpy()\n",
    "            true_bboxes = true_bboxes.cpu().numpy()\n",
    "            preds = preds.cpu().numpy()\n",
    "            pred_bboxes = pred_bboxes.cpu().numpy()\n",
    "\n",
    "            for img, true_box, true_label, pred_box, pred_label in zip(\n",
    "                images, true_bboxes, true_labels, pred_bboxes, preds\n",
    "            ):\n",
    "                if samples_visualized >= num_samples:\n",
    "                    return\n",
    "\n",
    "                fig, ax = plt.subplots(1)\n",
    "                img = np.transpose(img, (1, 2, 0))  # Convert from (C, H, W) to (H, W, C)\n",
    "                ax.imshow(img)\n",
    "\n",
    "                # Plot Ground Truth Bounding Box\n",
    "                gt_xmin, gt_ymin, gt_xmax, gt_ymax = true_box\n",
    "                gt_width = gt_xmax - gt_xmin\n",
    "                gt_height = gt_ymax - gt_ymin\n",
    "                gt_rect = patches.Rectangle(\n",
    "                    (gt_xmin, gt_ymin), gt_width, gt_height, \n",
    "                    linewidth=2, edgecolor='g', facecolor='none', label='Ground Truth'\n",
    "                )\n",
    "                ax.add_patch(gt_rect)\n",
    "\n",
    "                # Plot Predicted Bounding Box\n",
    "                pred_xmin, pred_ymin, pred_xmax, pred_ymax = pred_box\n",
    "                pred_width = pred_xmax - pred_xmin\n",
    "                pred_height = pred_ymax - pred_ymin\n",
    "                pred_rect = patches.Rectangle(\n",
    "                    (pred_xmin, pred_ymin), pred_width, pred_height, \n",
    "                    linewidth=2, edgecolor='r', facecolor='none', label='Prediction'\n",
    "                )\n",
    "                ax.add_patch(pred_rect)\n",
    "\n",
    "                # Add Labels\n",
    "                gt_class = label_encoder.inverse_transform([true_label])[0]\n",
    "                pred_class = label_encoder.inverse_transform([pred_label])[0]\n",
    "                plt.title(f\"GT: {gt_class} | Pred: {pred_class}\")\n",
    "\n",
    "                # Create Legend\n",
    "                handles = [\n",
    "                    patches.Patch(color='g', label='Ground Truth'),\n",
    "                    patches.Patch(color='r', label='Prediction')\n",
    "                ]\n",
    "                plt.legend(handles=handles)\n",
    "\n",
    "                plt.show()\n",
    "\n",
    "                samples_visualized += 1\n",
    "\n",
    "# -----------------------------\n",
    "# 7. Model Evaluation\n",
    "# -----------------------------\n",
    "\n",
    "# Load the trained model weights (already saved in 'custom_cnn_model.pth')\n",
    "if os.path.exists(model_weights_path):\n",
    "    model.load_state_dict(torch.load(model_weights_path, map_location=device))\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    print(f\"\\nModel loaded from '{model_weights_path}' and set to evaluation mode.\")\n",
    "else:\n",
    "    print(f\"\\nModel weights file '{model_weights_path}' not found. Please ensure the file exists.\")\n",
    "    # Optionally, exit the script or proceed without evaluation\n",
    "    exit()\n",
    "\n",
    "# Evaluate Classification\n",
    "evaluate_classification(model, val_loader, device)\n",
    "\n",
    "# Evaluate Bounding Boxes\n",
    "evaluate_bounding_boxes(model, val_loader, device, iou_threshold=0.5)\n",
    "\n",
    "# Visualize Predictions (Optional)\n",
    "visualize_predictions(model, val_loader, device, label_encoder, num_samples=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Setup and Configuration\n",
    "# -----------------------------\n",
    "\n",
    "# Set device to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Paths\n",
    "train_csv_path = 'Train.csv'  # Path to your training CSV\n",
    "images_dir = 'datasets/dataset/images/train'  # Path to your images directory\n",
    "model_weights_path = 'custom_cnn_model.pth'  # Path to save/load your model weights\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Data Preparation\n",
    "# -----------------------------\n",
    "\n",
    "# Load train data\n",
    "train = pd.read_csv(train_csv_path)\n",
    "\n",
    "# Encode class labels into numerical format using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "train['class'] = label_encoder.fit_transform(train['class'])\n",
    "\n",
    "# Check for missing image files and filter them out\n",
    "valid_images = [img_id for img_id in train['Image_ID'] if os.path.exists(os.path.join(images_dir, img_id))]\n",
    "train = train[train['Image_ID'].isin(valid_images)].reset_index(drop=True)\n",
    "\n",
    "print(f\"Number of training samples after filtering: {len(train)}\")\n",
    "\n",
    "# Split data into training and validation sets (80% train, 20% val)\n",
    "train_df, val_df = train_test_split(\n",
    "    train, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=train['class']\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(train_df)}, Validation samples: {len(val_df)}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Dataset and DataLoader\n",
    "# -----------------------------\n",
    "\n",
    "# Define a Custom Dataset Class for Loading Images and Annotations\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, images_dir, transforms=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.images_dir = images_dir\n",
    "        self.transforms = transforms if transforms else transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_id = self.dataframe.iloc[idx]['Image_ID']\n",
    "        image_path = os.path.join(self.images_dir, image_id)\n",
    "        \n",
    "        # Load and preprocess the image\n",
    "        try:\n",
    "            image = Image.open(image_path).convert(\"RGB\")\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Error loading image {image_path}: {e}\")\n",
    "        \n",
    "        # Extract bounding box coordinates\n",
    "        bbox = torch.tensor(\n",
    "            [self.dataframe.iloc[idx][c] for c in ['xmin', 'ymin', 'xmax', 'ymax']], \n",
    "            dtype=torch.float32\n",
    "        )\n",
    "        \n",
    "        # Extract class label\n",
    "        label = torch.tensor(self.dataframe.iloc[idx]['class'], dtype=torch.long)\n",
    "        \n",
    "        # Apply transformations\n",
    "        if self.transforms:\n",
    "            image = self.transforms(image)\n",
    "        \n",
    "        return image, {'boxes': bbox, 'labels': label}\n",
    "\n",
    "# Define transformations for the images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),  # Resize images to 256x256\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Instantiate the training dataset and DataLoader\n",
    "train_dataset = CustomDataset(dataframe=train_df, images_dir=images_dir, transforms=transform)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=16,          # Adjust based on your GPU memory\n",
    "    shuffle=True,           # Shuffle for training\n",
    "    num_workers=0,          # Set to 0 for easier debugging\n",
    "    pin_memory=True         # Copy tensors into CUDA pinned memory\n",
    ")\n",
    "\n",
    "# Instantiate the validation dataset and DataLoader\n",
    "val_dataset = CustomDataset(dataframe=val_df, images_dir=images_dir, transforms=transform)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=16,          # Adjust based on your GPU memory\n",
    "    shuffle=False,          # No need to shuffle for evaluation\n",
    "    num_workers=0,          # Set to 0 for easier debugging\n",
    "    pin_memory=True         # Copy tensors into CUDA pinned memory\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Model Definition\n",
    "# -----------------------------\n",
    "\n",
    "# Define the CustomCNN model\n",
    "class CustomCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CustomCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.flattened_size = self._get_flattened_size()\n",
    "        self.fc1 = nn.Linear(self.flattened_size, 256)\n",
    "        self.fc2_bbox = nn.Linear(256, 4)      # Bounding box coordinates [xmin, ymin, xmax, ymax]\n",
    "        self.fc2_class = nn.Linear(256, num_classes)  # Class prediction\n",
    "\n",
    "    def _get_flattened_size(self):\n",
    "        dummy_input = torch.zeros(1, 3, 256, 256)\n",
    "        dummy_output = self._forward_conv(dummy_input)\n",
    "        return dummy_output.view(1, -1).size(1)\n",
    "\n",
    "    def _forward_conv(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self._forward_conv(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        bbox_output = self.fc2_bbox(x)\n",
    "        class_output = self.fc2_class(x)\n",
    "        return bbox_output, class_output\n",
    "\n",
    "# Define number of classes based on unique labels\n",
    "num_classes = len(train['class'].unique())\n",
    "\n",
    "# Instantiate the model and move to the correct device\n",
    "model = CustomCNN(num_classes=num_classes).to(device)\n",
    "\n",
    "# Print the model structure (optional)\n",
    "print(f\"Custom CNN Model:\\n{model}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Training Loop\n",
    "# -----------------------------\n",
    "\n",
    "# Define loss functions and optimizer\n",
    "bbox_loss_fn = nn.MSELoss()\n",
    "class_loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 1\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nStarting Epoch {epoch + 1}/{num_epochs}\")\n",
    "    model.train()\n",
    "    total_bbox_loss, total_class_loss = 0.0, 0.0\n",
    "\n",
    "    for batch_idx, (images, targets) in enumerate(tqdm(train_loader, desc=\"Training\")):\n",
    "        # Skip batches where images or targets are None\n",
    "        if images is None or targets is None:\n",
    "            print(f\"Skipping batch {batch_idx + 1} due to None values.\")\n",
    "            continue\n",
    "\n",
    "        # Move data to the correct device\n",
    "        images = images.to(device)\n",
    "        bboxes = targets['boxes'].to(device)\n",
    "        labels = targets['labels'].to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        pred_bboxes, pred_labels = model(images)\n",
    "\n",
    "        # Calculate losses\n",
    "        bbox_loss = bbox_loss_fn(pred_bboxes, bboxes)\n",
    "        class_loss = class_loss_fn(pred_labels, labels)\n",
    "        total_loss = bbox_loss + class_loss\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate losses\n",
    "        total_bbox_loss += bbox_loss.item()\n",
    "        total_class_loss += class_loss.item()\n",
    "\n",
    "    avg_bbox_loss = total_bbox_loss / len(train_loader)\n",
    "    avg_class_loss = total_class_loss / len(train_loader)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], BBox Loss: {avg_bbox_loss:.4f}, Class Loss: {avg_class_loss:.4f}')\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), model_weights_path)\n",
    "print(f\"\\nModel saved to '{model_weights_path}'\")\n",
    "\n",
    "# -----------------------------\n",
    "# 6. Evaluation Metrics\n",
    "# -----------------------------\n",
    "\n",
    "def calculate_iou(box1, box2):\n",
    "    \"\"\"\n",
    "    Calculate Intersection over Union (IoU) between two bounding boxes.\n",
    "    Boxes are in the format [xmin, ymin, xmax, ymax]\n",
    "    \"\"\"\n",
    "    x_left = max(box1[0], box2[0])\n",
    "    y_top    = max(box1[1], box2[1])\n",
    "    x_right  = min(box1[2], box2[2])\n",
    "    y_bottom = min(box1[3], box2[3])\n",
    "\n",
    "    if x_right < x_left or y_bottom < y_top:\n",
    "        return 0.0  # No overlap\n",
    "\n",
    "    intersection_area = (x_right - x_left) * (y_bottom - y_top)\n",
    "    box1_area = (box1[2]-box1[0]) * (box1[3]-box1[1])\n",
    "    box2_area = (box2[2]-box2[0]) * (box2[3]-box2[1])\n",
    "    iou = intersection_area / float(box1_area + box2_area - intersection_area)\n",
    "    return iou\n",
    "\n",
    "def evaluate_classification(model, dataloader, device):\n",
    "    \"\"\"\n",
    "    Evaluate classification performance: Accuracy, Precision, Recall, F1-Score, Confusion Matrix\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, targets in tqdm(dataloader, desc=\"Evaluating Classification\"):\n",
    "            # Skip batches where images or targets are None\n",
    "            if images is None or targets is None:\n",
    "                continue\n",
    "\n",
    "            images = images.to(device)\n",
    "            labels = targets['labels'].to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            _, preds = model(images)  # Assuming model returns (bbox, class)\n",
    "            preds = torch.argmax(preds, dim=1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        all_labels, all_preds, average='weighted', zero_division=0\n",
    "    )\n",
    "    conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "    print(\"\\n--- Classification Evaluation ---\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision (Weighted): {precision:.4f}\")\n",
    "    print(f\"Recall (Weighted): {recall:.4f}\")\n",
    "    print(f\"F1-Score (Weighted): {f1:.4f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "\n",
    "def evaluate_bounding_boxes(model, dataloader, device, iou_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Evaluate bounding box predictions: Mean IoU and Precision at IoU threshold\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_iou = []\n",
    "    matched = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, targets in tqdm(dataloader, desc=\"Evaluating Bounding Boxes\"):\n",
    "            # Skip batches where images or targets are None\n",
    "            if images is None or targets is None:\n",
    "                continue\n",
    "\n",
    "            images = images.to(device)\n",
    "            true_bboxes = targets['boxes'].to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            pred_bboxes, _ = model(images)\n",
    "\n",
    "            # Move tensors to CPU for processing\n",
    "            pred_bboxes = pred_bboxes.cpu().numpy()\n",
    "            true_bboxes = true_bboxes.cpu().numpy()\n",
    "\n",
    "            # Iterate over each prediction and true box\n",
    "            for pred_box, true_box in zip(pred_bboxes, true_bboxes):\n",
    "                iou = calculate_iou(pred_box, true_box)\n",
    "                all_iou.append(iou)\n",
    "                if iou >= iou_threshold:\n",
    "                    matched += 1\n",
    "                total += 1\n",
    "\n",
    "    # Calculate metrics\n",
    "    mean_iou = np.mean(all_iou) if all_iou else 0\n",
    "    precision_at_iou = matched / total if total > 0 else 0\n",
    "\n",
    "    print(\"\\n--- Bounding Box Evaluation ---\")\n",
    "    print(f\"Mean IoU: {mean_iou:.4f}\")\n",
    "    print(f\"Precision at IoU >= {iou_threshold}: {precision_at_iou:.4f}\")\n",
    "\n",
    "def visualize_predictions(model, dataloader, device, label_encoder, num_samples=5):\n",
    "    \"\"\"\n",
    "    Visualize a few samples of ground truth and predicted bounding boxes along with class labels\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    samples_visualized = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, targets in dataloader:\n",
    "            # Skip batches where images or targets are None\n",
    "            if images is None or targets is None:\n",
    "                continue\n",
    "\n",
    "            images = images.to(device)\n",
    "            true_bboxes = targets['boxes'].to(device)\n",
    "            true_labels = targets['labels'].to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            pred_bboxes, pred_labels = model(images)\n",
    "            preds = torch.argmax(pred_labels, dim=1)\n",
    "\n",
    "            # Move tensors to CPU for visualization\n",
    "            images = images.cpu().numpy()\n",
    "            true_bboxes = true_bboxes.cpu().numpy()\n",
    "            preds = preds.cpu().numpy()\n",
    "            pred_bboxes = pred_bboxes.cpu().numpy()\n",
    "\n",
    "            for img, true_box, true_label, pred_box, pred_label in zip(\n",
    "                images, true_bboxes, true_labels, pred_bboxes, preds\n",
    "            ):\n",
    "                if samples_visualized >= num_samples:\n",
    "                    return\n",
    "\n",
    "                fig, ax = plt.subplots(1)\n",
    "                img = np.transpose(img, (1, 2, 0))  # Convert from (C, H, W) to (H, W, C)\n",
    "                ax.imshow(img)\n",
    "\n",
    "                # Plot Ground Truth Bounding Box\n",
    "                gt_xmin, gt_ymin, gt_xmax, gt_ymax = true_box\n",
    "                gt_width = gt_xmax - gt_xmin\n",
    "                gt_height = gt_ymax - gt_ymin\n",
    "                gt_rect = patches.Rectangle(\n",
    "                    (gt_xmin, gt_ymin), gt_width, gt_height, \n",
    "                    linewidth=2, edgecolor='g', facecolor='none', label='Ground Truth'\n",
    "                )\n",
    "                ax.add_patch(gt_rect)\n",
    "\n",
    "                # Plot Predicted Bounding Box\n",
    "                pred_xmin, pred_ymin, pred_xmax, pred_ymax = pred_box\n",
    "                pred_width = pred_xmax - pred_xmin\n",
    "                pred_height = pred_ymax - pred_ymin\n",
    "                pred_rect = patches.Rectangle(\n",
    "                    (pred_xmin, pred_ymin), pred_width, pred_height, \n",
    "                    linewidth=2, edgecolor='r', facecolor='none', label='Prediction'\n",
    "                )\n",
    "                ax.add_patch(pred_rect)\n",
    "\n",
    "                # Add Labels\n",
    "                gt_class = label_encoder.inverse_transform([true_label])[0]\n",
    "                pred_class = label_encoder.inverse_transform([pred_label])[0]\n",
    "                plt.title(f\"GT: {gt_class} | Pred: {pred_class}\")\n",
    "\n",
    "                # Create Legend\n",
    "                handles = [\n",
    "                    patches.Patch(color='g', label='Ground Truth'),\n",
    "                    patches.Patch(color='r', label='Prediction')\n",
    "                ]\n",
    "                plt.legend(handles=handles)\n",
    "\n",
    "                plt.show()\n",
    "\n",
    "                samples_visualized += 1\n",
    "\n",
    "# -----------------------------\n",
    "# 7. Model Evaluation\n",
    "# -----------------------------\n",
    "\n",
    "# Load the trained model weights (already saved in 'custom_cnn_model.pth')\n",
    "if os.path.exists(model_weights_path):\n",
    "    try:\n",
    "        model.load_state_dict(torch.load(model_weights_path, map_location=device))\n",
    "        model.eval()  # Set model to evaluation mode\n",
    "        print(f\"\\nModel loaded from '{model_weights_path}' and set to evaluation mode.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError loading model weights: {e}\")\n",
    "        exit()\n",
    "else:\n",
    "    print(f\"\\nModel weights file '{model_weights_path}' not found. Please ensure the file exists.\")\n",
    "    exit()\n",
    "\n",
    "# Evaluate Classification\n",
    "evaluate_classification(model, val_loader, device)\n",
    "\n",
    "# Evaluate Bounding Boxes\n",
    "evaluate_bounding_boxes(model, val_loader, device, iou_threshold=0.5)\n",
    "\n",
    "# Visualize Predictions (Optional)\n",
    "visualize_predictions(model, val_loader, device, label_encoder, num_samples=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import os\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "# import torch.nn.functional as F\n",
    "# from PIL import Image\n",
    "# from tqdm import tqdm\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.patches as patches\n",
    "# import torchvision.transforms as transforms\n",
    "\n",
    "# # -----------------------------\n",
    "# # 1. Setup and Configuration\n",
    "# # -----------------------------\n",
    "\n",
    "# # Set device to GPU if available\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(f\"Using device: {device}\")\n",
    "\n",
    "# # Paths\n",
    "# train_csv_path = 'Train.csv'  # Path to your training CSV\n",
    "# images_dir = 'datasets/dataset/images/compressed/train'  # Path to your images directory\n",
    "# model_weights_path = 'custom_cnn_model.pth'  # Path to save/load your model weights\n",
    "\n",
    "# # -----------------------------\n",
    "# # 2. Data Preparation\n",
    "# # -----------------------------\n",
    "\n",
    "# # Load train data\n",
    "# train = pd.read_csv(train_csv_path)\n",
    "\n",
    "# # Encode class labels into numerical format using LabelEncoder\n",
    "# label_encoder = LabelEncoder()\n",
    "# train['class'] = label_encoder.fit_transform(train['class'])\n",
    "\n",
    "# # Check for missing image files and filter them out\n",
    "# valid_images = [img_id for img_id in train['Image_ID'] if os.path.exists(os.path.join(images_dir, img_id))]\n",
    "# train = train[train['Image_ID'].isin(valid_images)].reset_index(drop=True)\n",
    "\n",
    "# print(f\"Number of training samples after filtering: {len(train)}\")\n",
    "\n",
    "# # Split data into training and validation sets (80% train, 20% val)\n",
    "# train_df, val_df = train_test_split(\n",
    "#     train, \n",
    "#     test_size=0.2, \n",
    "#     random_state=42, \n",
    "#     stratify=train['class']\n",
    "# )\n",
    "\n",
    "# print(f\"Training samples: {len(train_df)}, Validation samples: {len(val_df)}\")\n",
    "\n",
    "# # -----------------------------\n",
    "# # 3. Dataset and DataLoader\n",
    "# # -----------------------------\n",
    "\n",
    "# # Define a Custom Dataset Class for Loading Images and Annotations\n",
    "# class CustomDataset(Dataset):\n",
    "#     def __init__(self, dataframe, images_dir, transforms=None):\n",
    "#         self.dataframe = dataframe\n",
    "#         self.images_dir = images_dir\n",
    "#         self.transforms = transforms if transforms else transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.dataframe)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         image_id = self.dataframe.iloc[idx]['Image_ID']\n",
    "#         image_path = os.path.join(self.images_dir, image_id)\n",
    "        \n",
    "#         # Load and preprocess the image\n",
    "#         try:\n",
    "#             image = Image.open(image_path).convert(\"RGB\")\n",
    "#         except Exception as e:\n",
    "#             raise RuntimeError(f\"Error loading image {image_path}: {e}\")\n",
    "        \n",
    "#         # Extract bounding box coordinates\n",
    "#         bbox = torch.tensor(\n",
    "#             [self.dataframe.iloc[idx][c] for c in ['xmin', 'ymin', 'xmax', 'ymax']], \n",
    "#             dtype=torch.float32\n",
    "#         )\n",
    "        \n",
    "#         # Extract class label\n",
    "#         label = torch.tensor(self.dataframe.iloc[idx]['class'], dtype=torch.long)\n",
    "        \n",
    "#         # Apply transformations\n",
    "#         if self.transforms:\n",
    "#             image = self.transforms(image)\n",
    "        \n",
    "#         return image, {'boxes': bbox, 'labels': label}\n",
    "\n",
    "# # Define transformations for the images\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.Resize((256, 256)),  # Resize images to 256x256\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=[0.485, 0.456, 0.406],  # ImageNet mean\n",
    "#                          std=[0.229, 0.224, 0.225])   # ImageNet std\n",
    "# ])\n",
    "\n",
    "# # Instantiate the training dataset and DataLoader\n",
    "# train_dataset = CustomDataset(dataframe=train_df, images_dir=images_dir, transforms=transform)\n",
    "# train_loader = DataLoader(\n",
    "#     train_dataset, \n",
    "#     batch_size=32,          # Adjust based on your GPU memory\n",
    "#     shuffle=True,           # Shuffle for training\n",
    "#     num_workers=0,          # Set to 0 for easier debugging\n",
    "#     pin_memory=True         # Copy tensors into CUDA pinned memory\n",
    "# )\n",
    "\n",
    "# # Instantiate the validation dataset and DataLoader\n",
    "# val_dataset = CustomDataset(dataframe=val_df, images_dir=images_dir, transforms=transform)\n",
    "# val_loader = DataLoader(\n",
    "#     val_dataset, \n",
    "#     batch_size=32,          # Adjust based on your GPU memory\n",
    "#     shuffle=False,          # No need to shuffle for evaluation\n",
    "#     num_workers=0,          # Set to 0 for easier debugging\n",
    "#     pin_memory=True         # Copy tensors into CUDA pinned memory\n",
    "# )\n",
    "\n",
    "# # -----------------------------\n",
    "# # 4. Model Definition\n",
    "# # -----------------------------\n",
    "\n",
    "# # Define the CustomCNN model\n",
    "# class CustomCNN(nn.Module):\n",
    "#     def __init__(self, num_classes):\n",
    "#         super(CustomCNN, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
    "#         self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "#         self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "#         self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "#         self.flattened_size = self._get_flattened_size()\n",
    "#         self.fc1 = nn.Linear(self.flattened_size, 256)\n",
    "#         self.fc2_bbox = nn.Linear(256, 4)      # Bounding box coordinates [xmin, ymin, xmax, ymax]\n",
    "#         self.fc2_class = nn.Linear(256, num_classes)  # Class prediction\n",
    "\n",
    "#     def _get_flattened_size(self):\n",
    "#         dummy_input = torch.zeros(1, 3, 256, 256)\n",
    "#         dummy_output = self._forward_conv(dummy_input)\n",
    "#         return dummy_output.view(1, -1).size(1)\n",
    "\n",
    "#     def _forward_conv(self, x):\n",
    "#         x = self.pool(F.relu(self.conv1(x)))\n",
    "#         x = self.pool(F.relu(self.conv2(x)))\n",
    "#         x = self.pool(F.relu(self.conv3(x)))\n",
    "#         return x\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self._forward_conv(x)\n",
    "#         x = x.view(x.size(0), -1)\n",
    "#         x = F.relu(self.fc1(x))\n",
    "#         bbox_output = self.fc2_bbox(x)\n",
    "#         class_output = self.fc2_class(x)\n",
    "#         return bbox_output, class_output\n",
    "\n",
    "# # Define number of classes based on unique labels\n",
    "# num_classes = len(train['class'].unique())\n",
    "\n",
    "# # Instantiate the model and move to the correct device\n",
    "# model = CustomCNN(num_classes=num_classes).to(device)\n",
    "\n",
    "# # Print the model structure (optional)\n",
    "# print(f\"Custom CNN Model:\\n{model}\")\n",
    "\n",
    "# # -----------------------------\n",
    "# # 5. Training Loop\n",
    "# # -----------------------------\n",
    "\n",
    "# # Define loss functions and optimizer\n",
    "\n",
    "# # IoU Loss Function\n",
    "# class IoULoss(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(IoULoss, self).__init__()\n",
    "\n",
    "#     def forward(self, pred_boxes, target_boxes):\n",
    "#         # Convert boxes from (xmin, ymin, xmax, ymax) to (x1, y1, x2, y2)\n",
    "#         pred_boxes = torch.sigmoid(pred_boxes)  # Ensure predictions are between 0 and 1\n",
    "#         target_boxes = torch.sigmoid(target_boxes)\n",
    "        \n",
    "#         # Intersection coordinates\n",
    "#         x1 = torch.max(pred_boxes[:, 0], target_boxes[:, 0])\n",
    "#         y1 = torch.max(pred_boxes[:, 1], target_boxes[:, 1])\n",
    "#         x2 = torch.min(pred_boxes[:, 2], target_boxes[:, 2])\n",
    "#         y2 = torch.min(pred_boxes[:, 3], target_boxes[:, 3])\n",
    "        \n",
    "#         # Intersection area\n",
    "#         intersection = (x2 - x1).clamp(min=0) * (y2 - y1).clamp(min=0)\n",
    "        \n",
    "#         # Areas of the boxes\n",
    "#         pred_area = (pred_boxes[:, 2] - pred_boxes[:, 0]).clamp(min=0) * \\\n",
    "#                     (pred_boxes[:, 3] - pred_boxes[:, 1]).clamp(min=0)\n",
    "#         target_area = (target_boxes[:, 2] - target_boxes[:, 0]).clamp(min=0) * \\\n",
    "#                       (target_boxes[:, 3] - target_boxes[:, 1]).clamp(min=0)\n",
    "        \n",
    "#         # Union area\n",
    "#         union = pred_area + target_area - intersection + 1e-6  # Add epsilon to prevent division by zero\n",
    "        \n",
    "#         # IoU\n",
    "#         iou = intersection / union\n",
    "        \n",
    "#         # IoU Loss\n",
    "#         loss = 1 - iou\n",
    "#         return loss.mean()\n",
    "\n",
    "# # Initialize IoU Loss\n",
    "# iou_loss_fn = IoULoss()\n",
    "\n",
    "# # Cross Entropy Loss for classification\n",
    "# class_loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# # Optimizer\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# # Learning Rate Scheduler (Optional)\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "\n",
    "# # Training loop with validation\n",
    "# num_epochs = 1  # Increased from 1 to 5\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     print(f\"\\n=== Epoch {epoch + 1}/{num_epochs} ===\")\n",
    "#     model.train()\n",
    "#     total_iou_loss, total_class_loss = 0.0, 0.0\n",
    "#     train_loader_iter = tqdm(train_loader, desc=\"Training\", leave=False)\n",
    "    \n",
    "#     for batch_idx, (images, targets) in enumerate(train_loader_iter):\n",
    "#         # Skip batches where images or targets are None\n",
    "#         if images is None or targets is None:\n",
    "#             print(f\"Skipping batch {batch_idx + 1} due to None values.\")\n",
    "#             continue\n",
    "\n",
    "#         # Move data to the correct device\n",
    "#         images = images.to(device)\n",
    "#         bboxes = targets['boxes'].to(device)\n",
    "#         labels = targets['labels'].to(device)\n",
    "\n",
    "#         # Forward pass\n",
    "#         pred_bboxes, pred_labels = model(images)\n",
    "\n",
    "#         # Calculate losses\n",
    "#         bbox_loss = iou_loss_fn(pred_bboxes, bboxes)\n",
    "#         class_loss = class_loss_fn(pred_labels, labels)\n",
    "#         total_loss = bbox_loss + class_loss\n",
    "\n",
    "#         # Backward pass and optimization\n",
    "#         optimizer.zero_grad()\n",
    "#         total_loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         # Accumulate losses\n",
    "#         total_iou_loss += bbox_loss.item()\n",
    "#         total_class_loss += class_loss.item()\n",
    "\n",
    "#         # Update progress bar\n",
    "#         train_loader_iter.set_postfix({'IoU Loss': bbox_loss.item(), 'Class Loss': class_loss.item()})\n",
    "\n",
    "#     avg_iou_loss = total_iou_loss / len(train_loader)\n",
    "#     avg_class_loss = total_class_loss / len(train_loader)\n",
    "#     print(f\"Training Losses -> IoU Loss: {avg_iou_loss:.4f}, Class Loss: {avg_class_loss:.4f}\")\n",
    "\n",
    "#     # Step the scheduler\n",
    "#     scheduler.step()\n",
    "\n",
    "#     # -----------------------------\n",
    "#     # 6. Validation After Each Epoch\n",
    "#     # -----------------------------\n",
    "\n",
    "#     def calculate_iou(box1, box2):\n",
    "#         \"\"\"\n",
    "#         Calculate Intersection over Union (IoU) between two bounding boxes.\n",
    "#         Boxes are in the format [xmin, ymin, xmax, ymax]\n",
    "#         \"\"\"\n",
    "#         x_left = max(box1[0], box2[0])\n",
    "#         y_top    = max(box1[1], box2[1])\n",
    "#         x_right  = min(box1[2], box2[2])\n",
    "#         y_bottom = min(box1[3], box2[3])\n",
    "\n",
    "#         if x_right < x_left or y_bottom < y_top:\n",
    "#             return 0.0  # No overlap\n",
    "\n",
    "#         intersection_area = (x_right - x_left) * (y_bottom - y_top)\n",
    "#         box1_area = (box1[2]-box1[0]) * (box1[3]-box1[1])\n",
    "#         box2_area = (box2[2]-box2[0]) * (box2[3]-box2[1])\n",
    "#         iou = intersection_area / float(box1_area + box2_area - intersection_area)\n",
    "#         return iou\n",
    "\n",
    "#     def evaluate_classification(model, dataloader, device):\n",
    "#         \"\"\"\n",
    "#         Evaluate classification performance: Accuracy, Precision, Recall, F1-Score, Confusion Matrix\n",
    "#         \"\"\"\n",
    "#         model.eval()\n",
    "#         all_preds = []\n",
    "#         all_labels = []\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             for images, targets in tqdm(dataloader, desc=\"Validation Classification\", leave=False):\n",
    "#                 # Skip batches where images or targets are None\n",
    "#                 if images is None or targets is None:\n",
    "#                     continue\n",
    "\n",
    "#                 images = images.to(device)\n",
    "#                 labels = targets['labels'].to(device)\n",
    "\n",
    "#                 # Forward pass\n",
    "#                 _, preds = model(images)  # Assuming model returns (bbox, class)\n",
    "#                 preds = torch.argmax(preds, dim=1)\n",
    "\n",
    "#                 all_preds.extend(preds.cpu().numpy())\n",
    "#                 all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "#         # Calculate metrics\n",
    "#         accuracy = accuracy_score(all_labels, all_preds)\n",
    "#         precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "#             all_labels, all_preds, average='weighted', zero_division=0\n",
    "#         )\n",
    "#         conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "#         print(\"\\n--- Classification Evaluation ---\")\n",
    "#         print(f\"Accuracy: {accuracy:.4f}\")\n",
    "#         print(f\"Precision (Weighted): {precision:.4f}\")\n",
    "#         print(f\"Recall (Weighted): {recall:.4f}\")\n",
    "#         print(f\"F1-Score (Weighted): {f1:.4f}\")\n",
    "#         print(\"Confusion Matrix:\")\n",
    "#         print(conf_matrix)\n",
    "\n",
    "#     def evaluate_bounding_boxes(model, dataloader, device, iou_threshold=0.5):\n",
    "#         \"\"\"\n",
    "#         Evaluate bounding box predictions: Mean IoU and Precision at IoU threshold\n",
    "#         \"\"\"\n",
    "#         model.eval()\n",
    "#         all_iou = []\n",
    "#         matched = 0\n",
    "#         total = 0\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             for images, targets in tqdm(dataloader, desc=\"Validation Bounding Boxes\", leave=False):\n",
    "#                 # Skip batches where images or targets are None\n",
    "#                 if images is None or targets is None:\n",
    "#                     continue\n",
    "\n",
    "#                 images = images.to(device)\n",
    "#                 true_bboxes = targets['boxes'].to(device)\n",
    "\n",
    "#                 # Forward pass\n",
    "#                 pred_bboxes, _ = model(images)\n",
    "\n",
    "#                 # Move tensors to CPU for processing\n",
    "#                 pred_bboxes = pred_bboxes.cpu().numpy()\n",
    "#                 true_bboxes = true_bboxes.cpu().numpy()\n",
    "\n",
    "#                 # Iterate over each prediction and true box\n",
    "#                 for pred_box, true_box in zip(pred_bboxes, true_bboxes):\n",
    "#                     iou = calculate_iou(pred_box, true_box)\n",
    "#                     all_iou.append(iou)\n",
    "#                     if iou >= iou_threshold:\n",
    "#                         matched += 1\n",
    "#                     total += 1\n",
    "\n",
    "#         # Calculate metrics\n",
    "#         mean_iou = np.mean(all_iou) if all_iou else 0\n",
    "#         precision_at_iou = matched / total if total > 0 else 0\n",
    "\n",
    "#         print(\"\\n--- Bounding Box Evaluation ---\")\n",
    "#         print(f\"Mean IoU: {mean_iou:.4f}\")\n",
    "#         print(f\"Precision at IoU >= {iou_threshold}: {precision_at_iou:.4f}\")\n",
    "\n",
    "#     # Perform validation\n",
    "#     print(f\"\\n=== Validation After Epoch {epoch + 1} ===\")\n",
    "#     evaluate_classification(model, val_loader, device)\n",
    "#     evaluate_bounding_boxes(model, val_loader, device, iou_threshold=0.5)\n",
    "\n",
    "#     # -----------------------------\n",
    "#     # 7. Save the Trained Model\n",
    "#     # -----------------------------\n",
    "\n",
    "#     # Save the trained model after each epoch\n",
    "#     checkpoint_path = f'custom_cnn_model_epoch_{epoch + 1}.pth'\n",
    "#     torch.save(model.state_dict(), checkpoint_path)\n",
    "#     print(f\"Checkpoint saved to '{checkpoint_path}'\")\n",
    "\n",
    "# # -----------------------------\n",
    "# # 8. Final Evaluation (Optional)\n",
    "# # -----------------------------\n",
    "\n",
    "# # Load the best model (if saved separately)\n",
    "# # model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
    "# # model.eval()\n",
    "\n",
    "# # -----------------------------\n",
    "# # 9. Visualization of Predictions (Optional)\n",
    "# # -----------------------------\n",
    "\n",
    "# def visualize_predictions(model, dataloader, device, label_encoder, num_samples=5):\n",
    "#     \"\"\"\n",
    "#     Visualize a few samples of ground truth and predicted bounding boxes along with class labels\n",
    "#     \"\"\"\n",
    "#     model.eval()\n",
    "#     samples_visualized = 0\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for images, targets in dataloader:\n",
    "#             # Skip batches where images or targets are None\n",
    "#             if images is None or targets is None:\n",
    "#                 continue\n",
    "\n",
    "#             images = images.to(device)\n",
    "#             true_bboxes = targets['boxes'].to(device)\n",
    "#             true_labels = targets['labels'].to(device)\n",
    "\n",
    "#             # Forward pass\n",
    "#             pred_bboxes, pred_labels = model(images)\n",
    "#             preds = torch.argmax(pred_labels, dim=1)\n",
    "\n",
    "#             # Move tensors to CPU for visualization\n",
    "#             images = images.cpu().numpy()\n",
    "#             true_bboxes = true_bboxes.cpu().numpy()\n",
    "#             preds = preds.cpu().numpy()\n",
    "#             pred_bboxes = pred_bboxes.cpu().numpy()\n",
    "\n",
    "#             for img, true_box, true_label, pred_box, pred_label in zip(\n",
    "#                 images, true_bboxes, true_labels, pred_bboxes, preds\n",
    "#             ):\n",
    "#                 if samples_visualized >= num_samples:\n",
    "#                     return\n",
    "\n",
    "#                 fig, ax = plt.subplots(1)\n",
    "#                 img = np.transpose(img, (1, 2, 0))  # Convert from (C, H, W) to (H, W, C)\n",
    "#                 # Unnormalize the image for visualization\n",
    "#                 img = img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
    "#                 img = np.clip(img, 0, 1)\n",
    "#                 ax.imshow(img)\n",
    "\n",
    "#                 # Plot Ground Truth Bounding Box\n",
    "#                 gt_xmin, gt_ymin, gt_xmax, gt_ymax = true_box\n",
    "#                 gt_width = gt_xmax - gt_xmin\n",
    "#                 gt_height = gt_ymax - gt_ymin\n",
    "#                 gt_rect = patches.Rectangle(\n",
    "#                     (gt_xmin, gt_ymin), gt_width, gt_height, \n",
    "#                     linewidth=2, edgecolor='g', facecolor='none', label='Ground Truth'\n",
    "#                 )\n",
    "#                 ax.add_patch(gt_rect)\n",
    "\n",
    "#                 # Plot Predicted Bounding Box\n",
    "#                 pred_xmin, pred_ymin, pred_xmax, pred_ymax = pred_box\n",
    "#                 pred_width = pred_xmax - pred_xmin\n",
    "#                 pred_height = pred_ymax - pred_ymin\n",
    "#                 pred_rect = patches.Rectangle(\n",
    "#                     (pred_xmin, pred_ymin), pred_width, pred_height, \n",
    "#                     linewidth=2, edgecolor='r', facecolor='none', label='Prediction'\n",
    "#                 )\n",
    "#                 ax.add_patch(pred_rect)\n",
    "\n",
    "#                 # Add Labels\n",
    "#                 gt_class = label_encoder.inverse_transform([true_label])[0]\n",
    "#                 pred_class = label_encoder.inverse_transform([pred_label])[0]\n",
    "#                 plt.title(f\"GT: {gt_class} | Pred: {pred_class}\")\n",
    "\n",
    "#                 # Create Legend\n",
    "#                 handles = [\n",
    "#                     patches.Patch(color='g', label='Ground Truth'),\n",
    "#                     patches.Patch(color='r', label='Prediction')\n",
    "#                 ]\n",
    "#                 plt.legend(handles=handles)\n",
    "\n",
    "#                 plt.show()\n",
    "\n",
    "#                 samples_visualized += 1\n",
    "\n",
    "# # Visualize some predictions after training\n",
    "# print(\"\\n=== Visualizing Predictions on Validation Set ===\")\n",
    "# visualize_predictions(model, val_loader, device, label_encoder, num_samples=5)\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Setup and Configuration\n",
    "# -----------------------------\n",
    "\n",
    "# Set device to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Paths\n",
    "train_csv_path = 'Train.csv'  # Path to your training CSV\n",
    "images_dir = 'datasets/dataset/images/compressed/train'  # Path to your images directory\n",
    "model_weights_path = 'custom_cnn_model.pth'  # Path to save/load your model weights\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Data Preparation\n",
    "# -----------------------------\n",
    "\n",
    "# Load train data\n",
    "train = pd.read_csv(train_csv_path)\n",
    "\n",
    "# Encode class labels into numerical format using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "train['class'] = label_encoder.fit_transform(train['class'])\n",
    "\n",
    "# Check for missing image files and filter them out\n",
    "valid_images = [img_id for img_id in train['Image_ID'] if os.path.exists(os.path.join(images_dir, img_id))]\n",
    "train = train[train['Image_ID'].isin(valid_images)].reset_index(drop=True)\n",
    "\n",
    "print(f\"Number of training samples after filtering: {len(train)}\")\n",
    "\n",
    "# Split data into training and validation sets (80% train, 20% val)\n",
    "train_df, val_df = train_test_split(\n",
    "    train, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=train['class']\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(train_df)}, Validation samples: {len(val_df)}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Dataset and DataLoader\n",
    "# -----------------------------\n",
    "\n",
    "# Define a Custom Dataset Class for Loading Images and Annotations\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, images_dir, transforms=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.images_dir = images_dir\n",
    "        self.transforms = transforms if transforms else transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_id = self.dataframe.iloc[idx]['Image_ID']\n",
    "        image_path = os.path.join(self.images_dir, image_id)\n",
    "        \n",
    "        # Load and preprocess the image\n",
    "        try:\n",
    "            image = Image.open(image_path).convert(\"RGB\")\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Error loading image {image_path}: {e}\")\n",
    "        \n",
    "        # Extract bounding box coordinates\n",
    "        bbox = torch.tensor(\n",
    "            [self.dataframe.iloc[idx][c] for c in ['xmin', 'ymin', 'xmax', 'ymax']], \n",
    "            dtype=torch.float32\n",
    "        )\n",
    "        \n",
    "        # Extract class label\n",
    "        label = torch.tensor(self.dataframe.iloc[idx]['class'], dtype=torch.long)\n",
    "        \n",
    "        # Apply transformations\n",
    "        if self.transforms:\n",
    "            image = self.transforms(image)\n",
    "        \n",
    "        return image, {'boxes': bbox, 'labels': label}\n",
    "\n",
    "# Define transformations for the images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),  # Resize images to 256x256\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],  # ImageNet mean\n",
    "                         std=[0.229, 0.224, 0.225])   # ImageNet std\n",
    "])\n",
    "\n",
    "# Instantiate the training dataset and DataLoader\n",
    "train_dataset = CustomDataset(dataframe=train_df, images_dir=images_dir, transforms=transform)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=64,          # Adjust based on your GPU memory\n",
    "    shuffle=True,           # Shuffle for training\n",
    "    num_workers=0,          # Set to 0 for easier debugging\n",
    "    pin_memory=True         # Copy tensors into CUDA pinned memory\n",
    ")\n",
    "\n",
    "# Instantiate the validation dataset and DataLoader\n",
    "val_dataset = CustomDataset(dataframe=val_df, images_dir=images_dir, transforms=transform)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=64,          # Adjust based on your GPU memory\n",
    "    shuffle=False,          # No need to shuffle for evaluation\n",
    "    num_workers=0,          # Set to 0 for easier debugging\n",
    "    pin_memory=True         # Copy tensors into CUDA pinned memory\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Reduced Size Model Definition\n",
    "# -----------------------------\n",
    "\n",
    "# # Define the smaller CustomCNN model\n",
    "# class SmallCustomCNN(nn.Module):\n",
    "#     def __init__(self, num_classes):\n",
    "#         super(SmallCustomCNN, self).__init__()\n",
    "#         # Reduced number of filters\n",
    "#         self.conv1 = nn.Conv2d(3, 8, kernel_size=3, padding=1)\n",
    "#         self.conv2 = nn.Conv2d(8, 16, kernel_size=3, padding=1)\n",
    "#         self.conv3 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "#         self.pool = nn.MaxPool2d(2, 2)\n",
    "#         # Global Average Pooling to reduce parameters\n",
    "#         self.global_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "#         # Reduced fully connected layers\n",
    "#         self.fc1 = nn.Linear(32, 64)\n",
    "#         self.fc2_bbox = nn.Linear(64, 4)      # Bounding box coordinates [xmin, ymin, xmax, ymax]\n",
    "#         self.fc2_class = nn.Linear(64, num_classes)  # Class prediction\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.pool(F.relu(self.conv1(x)))  # Output size: (batch, 8, H/2, W/2)\n",
    "#         x = self.pool(F.relu(self.conv2(x)))  # Output size: (batch, 16, H/4, W/4)\n",
    "#         x = self.pool(F.relu(self.conv3(x)))  # Output size: (batch, 32, H/8, W/8)\n",
    "#         x = self.global_pool(x)               # Output size: (batch, 32, 1, 1)\n",
    "#         x = x.view(x.size(0), -1)             # Flatten to (batch, 32)\n",
    "#         x = F.relu(self.fc1(x))               # (batch, 64)\n",
    "#         bbox_output = self.fc2_bbox(x)\n",
    "#         class_output = self.fc2_class(x)\n",
    "#         return bbox_output, class_output\n",
    "\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "class SmallCustomCNN(nn.Module):\n",
    "    def __init__(self, num_classes, input_size):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            num_classes (int): Number of target classes for classification.\n",
    "            input_size (int): The size of the flattened input image (e.g., 3*224*224 for RGB images of size 224x224).\n",
    "        \"\"\"\n",
    "        super(SmallCustomCNN, self).__init__()\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(input_size, 512)    # First hidden layer\n",
    "        self.fc2 = nn.Linear(512, 256)           # Second hidden layer\n",
    "        self.fc3 = nn.Linear(256, 128)           # Third hidden layer\n",
    "        self.fc4_bbox = nn.Linear(128, 4)        # Output layer for bounding box coordinates [xmin, ymin, xmax, ymax]\n",
    "        self.fc4_class = nn.Linear(128, num_classes)  # Output layer for class predictions\n",
    "\n",
    "        # Optional: Add dropout layers to prevent overfitting\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Defines the forward pass of the network.\n",
    "        \n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape (batch_size, channels, height, width).\n",
    "        \n",
    "        Returns:\n",
    "            bbox_output (torch.Tensor): Bounding box coordinates.\n",
    "            class_output (torch.Tensor): Class scores.\n",
    "        \"\"\"\n",
    "        # Flatten the input tensor\n",
    "        x = x.view(x.size(0), -1)  # Shape: (batch_size, input_size)\n",
    "        \n",
    "        # Pass through the first fully connected layer with ReLU activation\n",
    "        x = F.relu(self.fc1(x))    # Shape: (batch_size, 512)\n",
    "        x = self.dropout(x)         # Apply dropout\n",
    "        \n",
    "        # Pass through the second fully connected layer with ReLU activation\n",
    "        x = F.relu(self.fc2(x))    # Shape: (batch_size, 256)\n",
    "        x = self.dropout(x)         # Apply dropout\n",
    "        \n",
    "        # Pass through the third fully connected layer with ReLU activation\n",
    "        x = F.relu(self.fc3(x))    # Shape: (batch_size, 128)\n",
    "        x = self.dropout(x)         # Apply dropout\n",
    "        \n",
    "        # Output layers\n",
    "        bbox_output = self.fc4_bbox(x)   # Shape: (batch_size, 4)\n",
    "        class_output = self.fc4_class(x) # Shape: (batch_size, num_classes)\n",
    "        \n",
    "        return bbox_output, class_output\n",
    "\n",
    "\n",
    "# Define number of classes based on unique labels\n",
    "num_classes = len(train['class'].unique())\n",
    "\n",
    "# Instantiate the smaller model and move to the correct device\n",
    "model = SmallCustomCNN(num_classes=num_classes, input_size=196608).to(device)\n",
    "\n",
    "# Print the model structure (optional)\n",
    "print(f\"Small Custom CNN Model:\\n{model}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Training Loop\n",
    "# -----------------------------\n",
    "\n",
    "# Define loss functions and optimizer\n",
    "\n",
    "# IoU Loss Function (same as before)\n",
    "class IoULoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(IoULoss, self).__init__()\n",
    "\n",
    "    def forward(self, pred_boxes, target_boxes):\n",
    "        # Convert boxes from (xmin, ymin, xmax, ymax) to (x1, y1, x2, y2)\n",
    "        pred_boxes = torch.sigmoid(pred_boxes)  # Ensure predictions are between 0 and 1\n",
    "        target_boxes = torch.sigmoid(target_boxes)\n",
    "        \n",
    "        # Intersection coordinates\n",
    "        x1 = torch.max(pred_boxes[:, 0], target_boxes[:, 0])\n",
    "        y1 = torch.max(pred_boxes[:, 1], target_boxes[:, 1])\n",
    "        x2 = torch.min(pred_boxes[:, 2], target_boxes[:, 2])\n",
    "        y2 = torch.min(pred_boxes[:, 3], target_boxes[:, 3])\n",
    "        \n",
    "        # Intersection area\n",
    "        intersection = (x2 - x1).clamp(min=0) * (y2 - y1).clamp(min=0)\n",
    "        \n",
    "        # Areas of the boxes\n",
    "        pred_area = (pred_boxes[:, 2] - pred_boxes[:, 0]).clamp(min=0) * \\\n",
    "                    (pred_boxes[:, 3] - pred_boxes[:, 1]).clamp(min=0)\n",
    "        target_area = (target_boxes[:, 2] - target_boxes[:, 0]).clamp(min=0) * \\\n",
    "                      (target_boxes[:, 3] - target_boxes[:, 1]).clamp(min=0)\n",
    "        \n",
    "        # Union area\n",
    "        union = pred_area + target_area - intersection + 1e-6  # Add epsilon to prevent division by zero\n",
    "        \n",
    "        # IoU\n",
    "        iou = intersection / union\n",
    "        \n",
    "        # IoU Loss\n",
    "        loss = 1 - iou\n",
    "        return loss.mean()\n",
    "\n",
    "# Initialize IoU Loss\n",
    "iou_loss_fn = IoULoss()\n",
    "\n",
    "# Cross Entropy Loss for classification\n",
    "class_loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Learning Rate Scheduler (Optional)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "\n",
    "# Training loop with validation\n",
    "num_epochs = 1  # Adjust as needed\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\n=== Epoch {epoch + 1}/{num_epochs} ===\")\n",
    "    model.train()\n",
    "    total_iou_loss, total_class_loss = 0.0, 0.0\n",
    "    train_loader_iter = tqdm(train_loader, desc=\"Training\", leave=False)\n",
    "    \n",
    "    for batch_idx, (images, targets) in enumerate(train_loader_iter):\n",
    "        # Skip batches where images or targets are None\n",
    "        if images is None or targets is None:\n",
    "            print(f\"Skipping batch {batch_idx + 1} due to None values.\")\n",
    "            continue\n",
    "\n",
    "        # Move data to the correct device\n",
    "        images = images.to(device)\n",
    "        bboxes = targets['boxes'].to(device)\n",
    "        labels = targets['labels'].to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        pred_bboxes, pred_labels = model(images)\n",
    "\n",
    "        # Calculate losses\n",
    "        bbox_loss = iou_loss_fn(pred_bboxes, bboxes)\n",
    "        class_loss = class_loss_fn(pred_labels, labels)\n",
    "        total_loss = bbox_loss + class_loss\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate losses\n",
    "        total_iou_loss += bbox_loss.item()\n",
    "        total_class_loss += class_loss.item()\n",
    "\n",
    "        # Update progress bar\n",
    "        train_loader_iter.set_postfix({'IoU Loss': bbox_loss.item(), 'Class Loss': class_loss.item()})\n",
    "\n",
    "    avg_iou_loss = total_iou_loss / len(train_loader)\n",
    "    avg_class_loss = total_class_loss / len(train_loader)\n",
    "    print(f\"Training Losses -> IoU Loss: {avg_iou_loss:.4f}, Class Loss: {avg_class_loss:.4f}\")\n",
    "\n",
    "    # Step the scheduler\n",
    "    scheduler.step()\n",
    "\n",
    "    # -----------------------------\n",
    "    # 6. Validation After Each Epoch\n",
    "    # -----------------------------\n",
    "\n",
    "    def calculate_iou(box1, box2):\n",
    "        \"\"\"\n",
    "        Calculate Intersection over Union (IoU) between two bounding boxes.\n",
    "        Boxes are in the format [xmin, ymin, xmax, ymax]\n",
    "        \"\"\"\n",
    "        x_left = max(box1[0], box2[0])\n",
    "        y_top    = max(box1[1], box2[1])\n",
    "        x_right  = min(box1[2], box2[2])\n",
    "        y_bottom = min(box1[3], box2[3])\n",
    "\n",
    "        if x_right < x_left or y_bottom < y_top:\n",
    "            return 0.0  # No overlap\n",
    "\n",
    "        intersection_area = (x_right - x_left) * (y_bottom - y_top)\n",
    "        box1_area = (box1[2]-box1[0]) * (box1[3]-box1[1])\n",
    "        box2_area = (box2[2]-box2[0]) * (box2[3]-box2[1])\n",
    "        iou = intersection_area / float(box1_area + box2_area - intersection_area)\n",
    "        return iou\n",
    "\n",
    "    def evaluate_classification(model, dataloader, device):\n",
    "        \"\"\"\n",
    "        Evaluate classification performance: Accuracy, Precision, Recall, F1-Score, Confusion Matrix\n",
    "        \"\"\"\n",
    "        model.eval()\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, targets in tqdm(dataloader, desc=\"Validation Classification\", leave=False):\n",
    "                # Skip batches where images or targets are None\n",
    "                if images is None or targets is None:\n",
    "                    continue\n",
    "\n",
    "                images = images.to(device)\n",
    "                labels = targets['labels'].to(device)\n",
    "\n",
    "                # Forward pass\n",
    "                _, preds = model(images)  # Assuming model returns (bbox, class)\n",
    "                preds = torch.argmax(preds, dim=1)\n",
    "\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(all_labels, all_preds)\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "            all_labels, all_preds, average='weighted', zero_division=0\n",
    "        )\n",
    "        conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "        print(\"\\n--- Classification Evaluation ---\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Precision (Weighted): {precision:.4f}\")\n",
    "        print(f\"Recall (Weighted): {recall:.4f}\")\n",
    "        print(f\"F1-Score (Weighted): {f1:.4f}\")\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(conf_matrix)\n",
    "\n",
    "    def evaluate_bounding_boxes(model, dataloader, device, iou_threshold=0.5):\n",
    "        \"\"\"\n",
    "        Evaluate bounding box predictions: Mean IoU and Precision at IoU threshold\n",
    "        \"\"\"\n",
    "        model.eval()\n",
    "        all_iou = []\n",
    "        matched = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, targets in tqdm(dataloader, desc=\"Validation Bounding Boxes\", leave=False):\n",
    "                # Skip batches where images or targets are None\n",
    "                if images is None or targets is None:\n",
    "                    continue\n",
    "\n",
    "                images = images.to(device)\n",
    "                true_bboxes = targets['boxes'].to(device)\n",
    "\n",
    "                # Forward pass\n",
    "                pred_bboxes, _ = model(images)\n",
    "\n",
    "                # Move tensors to CPU for processing\n",
    "                pred_bboxes = pred_bboxes.cpu().numpy()\n",
    "                true_bboxes = true_bboxes.cpu().numpy()\n",
    "\n",
    "                # Iterate over each prediction and true box\n",
    "                for pred_box, true_box in zip(pred_bboxes, true_bboxes):\n",
    "                    iou = calculate_iou(pred_box, true_box)\n",
    "                    all_iou.append(iou)\n",
    "                    if iou >= iou_threshold:\n",
    "                        matched += 1\n",
    "                    total += 1\n",
    "\n",
    "        # Calculate metrics\n",
    "        mean_iou = np.mean(all_iou) if all_iou else 0\n",
    "        precision_at_iou = matched / total if total > 0 else 0\n",
    "\n",
    "        print(\"\\n--- Bounding Box Evaluation ---\")\n",
    "        print(f\"Mean IoU: {mean_iou:.4f}\")\n",
    "        print(f\"Precision at IoU >= {iou_threshold}: {precision_at_iou:.4f}\")\n",
    "\n",
    "    # Perform validation\n",
    "    print(f\"\\n=== Validation After Epoch {epoch + 1} ===\")\n",
    "    evaluate_classification(model, val_loader, device)\n",
    "    evaluate_bounding_boxes(model, val_loader, device, iou_threshold=0.5)\n",
    "\n",
    "    # -----------------------------\n",
    "    # 7. Save the Trained Model\n",
    "    # -----------------------------\n",
    "\n",
    "    # Save the trained model after each epoch\n",
    "    checkpoint_path = f'custom_cnn_model_epoch_{epoch + 1}.pth'\n",
    "    torch.save(model.state_dict(), checkpoint_path)\n",
    "    print(f\"Checkpoint saved to '{checkpoint_path}'\")\n",
    "\n",
    "# -----------------------------\n",
    "# 8. Visualization of Predictions (Optional)\n",
    "# -----------------------------\n",
    "\n",
    "def visualize_predictions(model, dataloader, device, label_encoder, num_samples=5):\n",
    "    \"\"\"\n",
    "    Visualize a few samples of ground truth and predicted bounding boxes along with class labels\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    samples_visualized = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, targets in dataloader:\n",
    "            # Skip batches where images or targets are None\n",
    "            if images is None or targets is None:\n",
    "                continue\n",
    "\n",
    "            images = images.to(device)\n",
    "            true_bboxes = targets['boxes'].to(device)\n",
    "            true_labels = targets['labels'].to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            pred_bboxes, pred_labels = model(images)\n",
    "            preds = torch.argmax(pred_labels, dim=1)\n",
    "\n",
    "            # Move tensors to CPU for visualization\n",
    "            images = images.cpu().numpy()\n",
    "            true_bboxes = true_bboxes.cpu().numpy()\n",
    "            preds = preds.cpu().numpy()\n",
    "            pred_bboxes = pred_bboxes.cpu().numpy()\n",
    "\n",
    "            for img, true_box, true_label, pred_box, pred_label in zip(\n",
    "                images, true_bboxes, true_labels, pred_bboxes, preds\n",
    "            ):\n",
    "                if samples_visualized >= num_samples:\n",
    "                    return\n",
    "\n",
    "                fig, ax = plt.subplots(1)\n",
    "                img = np.transpose(img, (1, 2, 0))  # Convert from (C, H, W) to (H, W, C)\n",
    "                # Unnormalize the image for visualization\n",
    "                img = img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
    "                img = np.clip(img, 0, 1)\n",
    "                ax.imshow(img)\n",
    "\n",
    "                # Plot Ground Truth Bounding Box\n",
    "                gt_xmin, gt_ymin, gt_xmax, gt_ymax = true_box\n",
    "                gt_width = gt_xmax - gt_xmin\n",
    "                gt_height = gt_ymax - gt_ymin\n",
    "                gt_rect = patches.Rectangle(\n",
    "                    (gt_xmin, gt_ymin), gt_width, gt_height, \n",
    "                    linewidth=2, edgecolor='g', facecolor='none', label='Ground Truth'\n",
    "                )\n",
    "                ax.add_patch(gt_rect)\n",
    "\n",
    "                # Plot Predicted Bounding Box\n",
    "                pred_xmin, pred_ymin, pred_xmax, pred_ymax = pred_box\n",
    "                pred_width = pred_xmax - pred_xmin\n",
    "                pred_height = pred_ymax - pred_ymin\n",
    "                pred_rect = patches.Rectangle(\n",
    "                    (pred_xmin, pred_ymin), pred_width, pred_height, \n",
    "                    linewidth=2, edgecolor='r', facecolor='none', label='Prediction'\n",
    "                )\n",
    "                ax.add_patch(pred_rect)\n",
    "\n",
    "                # Add Labels\n",
    "                gt_class = label_encoder.inverse_transform([true_label])[0]\n",
    "                pred_class = label_encoder.inverse_transform([pred_label])[0]\n",
    "                plt.title(f\"GT: {gt_class} | Pred: {pred_class}\")\n",
    "\n",
    "                # Create Legend\n",
    "                handles = [\n",
    "                    patches.Patch(color='g', label='Ground Truth'),\n",
    "                    patches.Patch(color='r', label='Prediction')\n",
    "                ]\n",
    "                plt.legend(handles=handles)\n",
    "\n",
    "                plt.show()\n",
    "\n",
    "                samples_visualized += 1\n",
    "\n",
    "# Visualize some predictions after training\n",
    "print(\"\\n=== Visualizing Predictions on Validation Set ===\")\n",
    "visualize_predictions(model, val_loader, device, label_encoder, num_samples=5)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Dataset Definition\n",
    "# -----------------------------\n",
    "\n",
    "class CachedDataset(Dataset):\n",
    "    def __init__(self, dataframe, cached_dir, original_image_size=(2560, 1440), resized_image_size=(128, 128)):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dataframe (pd.DataFrame): DataFrame containing image IDs, bbox coordinates, and class labels.\n",
    "            cached_dir (str): Directory where cached image tensors are stored.\n",
    "            original_image_size (tuple): Original image size as (width, height).\n",
    "            resized_image_size (tuple): Desired image size as (width, height).\n",
    "        \"\"\"\n",
    "        self.dataframe = dataframe\n",
    "        self.cached_dir = cached_dir\n",
    "        self.original_width, self.original_height = original_image_size\n",
    "        self.resized_width, self.resized_height = resized_image_size\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize(resized_image_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],  \n",
    "                                 std=[0.229, 0.224, 0.225])   \n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_id = self.dataframe.iloc[idx]['Image_ID']\n",
    "        cached_path = os.path.join(self.cached_dir, f\"{image_id}.pt\")\n",
    "        try:\n",
    "            image = torch.load(cached_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading cached image {cached_path}: {e}\")\n",
    "            # Return dummy data or handle appropriately\n",
    "            image = torch.zeros(3, self.resized_height, self.resized_width)  # Adjust size accordingly\n",
    "            bbox = torch.zeros(4, dtype=torch.float32)\n",
    "            label = torch.tensor(0, dtype=torch.long)\n",
    "            return image, {'boxes': bbox, 'labels': label}\n",
    "        \n",
    "        # Extract bounding box coordinates and scale them\n",
    "        # Assuming original bbox coordinates are based on original_image_size\n",
    "        bbox_original = [\n",
    "            self.dataframe.iloc[idx][c] for c in ['xmin', 'ymin', 'xmax', 'ymax']\n",
    "        ]\n",
    "        # Scale bbox coordinates to match resized images\n",
    "        scale_x = self.resized_width / self.original_width\n",
    "        scale_y = self.resized_height / self.original_height\n",
    "        bbox_scaled = [\n",
    "            bbox_original[0] * scale_x,\n",
    "            bbox_original[1] * scale_y,\n",
    "            bbox_original[2] * scale_x,\n",
    "            bbox_original[3] * scale_y\n",
    "        ]\n",
    "        # Clamp bbox coordinates to image boundaries\n",
    "        bbox_scaled = [\n",
    "            min(max(bbox_scaled[0], 0), self.resized_width),\n",
    "            min(max(bbox_scaled[1], 0), self.resized_height),\n",
    "            min(max(bbox_scaled[2], 0), self.resized_width),\n",
    "            min(max(bbox_scaled[3], 0), self.resized_height)\n",
    "        ]\n",
    "        bbox = torch.tensor(bbox_scaled, dtype=torch.float32)\n",
    "        \n",
    "        # Extract class label\n",
    "        label = torch.tensor(self.dataframe.iloc[idx]['class'], dtype=torch.long)\n",
    "        \n",
    "        # Debugging: Print fetched item details\n",
    "        if idx < 10:  # Limit to first 10 to avoid excessive logging\n",
    "            print(f\"Fetched index {idx}: Image_ID={image_id}, BBox={bbox}, Label={label}\")\n",
    "        \n",
    "        return image, {'boxes': bbox, 'labels': label}\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Model Definition\n",
    "# -----------------------------\n",
    "\n",
    "class CustomCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CustomCNN, self).__init__()\n",
    "        # Use a pretrained ResNet18 backbone with updated weights parameter\n",
    "        self.backbone = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "        num_features = self.backbone.fc.in_features\n",
    "        self.backbone.fc = nn.Identity()  # Remove the original FC layer\n",
    "        \n",
    "        # Define custom heads\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc_bbox = nn.Linear(num_features, 4)\n",
    "        self.fc_class = nn.Linear(num_features, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        features = self.dropout(features)\n",
    "        bbox_output = self.fc_bbox(features)\n",
    "        class_output = self.fc_class(features)\n",
    "        return bbox_output, class_output\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Helper Functions\n",
    "# -----------------------------\n",
    "\n",
    "def cache_images(dataframe, images_dir, cached_dir, transform):\n",
    "    \"\"\"\n",
    "    Preprocess and cache images by applying transformations and saving as tensors.\n",
    "    \n",
    "    Args:\n",
    "        dataframe (pd.DataFrame): DataFrame containing image information.\n",
    "        images_dir (str): Directory where original images are stored.\n",
    "        cached_dir (str): Directory to save cached image tensors.\n",
    "        transform (torchvision.transforms.Compose): Transformations to apply to images.\n",
    "    \"\"\"\n",
    "    print(\"Caching images...\")\n",
    "    for idx, row in tqdm(dataframe.iterrows(), total=len(dataframe)):\n",
    "        image_id = row['Image_ID']\n",
    "        image_path = os.path.join(images_dir, image_id)\n",
    "        cached_path = os.path.join(cached_dir, f\"{image_id}.pt\")\n",
    "        if not os.path.exists(cached_path):\n",
    "            try:\n",
    "                image = Image.open(image_path).convert(\"RGB\")\n",
    "                image = transform(image)\n",
    "                torch.save(image, cached_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Error caching image {image_id}: {e}\")\n",
    "\n",
    "def calculate_iou(box1, box2):\n",
    "    \"\"\"\n",
    "    Calculate Intersection over Union (IoU) between two bounding boxes.\n",
    "    \n",
    "    Args:\n",
    "        box1 (array-like): [xmin, ymin, xmax, ymax] for the first box.\n",
    "        box2 (array-like): [xmin, ymin, xmax, ymax] for the second box.\n",
    "    \n",
    "    Returns:\n",
    "        float: IoU value.\n",
    "    \"\"\"\n",
    "    x_left = max(box1[0], box2[0])\n",
    "    y_top    = max(box1[1], box2[1])\n",
    "    x_right  = min(box1[2], box2[2])\n",
    "    y_bottom = min(box1[3], box2[3])\n",
    "\n",
    "    if x_right < x_left or y_bottom < y_top:\n",
    "        return 0.0  # No overlap\n",
    "\n",
    "    intersection_area = (x_right - x_left) * (y_bottom - y_top)\n",
    "    box1_area = (box1[2]-box1[0]) * (box1[3]-box1[1])\n",
    "    box2_area = (box2[2]-box2[0]) * (box2[3]-box2[1])\n",
    "    iou = intersection_area / float(box1_area + box2_area - intersection_area)\n",
    "    return iou\n",
    "\n",
    "def evaluate_classification(model, dataloader, device):\n",
    "    \"\"\"\n",
    "    Evaluate classification performance on the validation set.\n",
    "    \n",
    "    Args:\n",
    "        model (nn.Module): Trained model.\n",
    "        dataloader (DataLoader): Validation DataLoader.\n",
    "        device (torch.device): Device to perform computations on.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, targets in tqdm(dataloader, desc=\"Validation Classification\", leave=False):\n",
    "            if images is None or targets is None:\n",
    "                continue\n",
    "\n",
    "            images = images.to(device, non_blocking=True)\n",
    "            labels = targets['labels'].to(device, non_blocking=True)\n",
    "\n",
    "            with autocast():\n",
    "                _, preds = model(images)\n",
    "                preds = torch.argmax(preds, dim=1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        all_labels, all_preds, average='weighted', zero_division=0\n",
    "    )\n",
    "    conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "    print(\"\\n--- Classification Evaluation ---\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision (Weighted): {precision:.4f}\")\n",
    "    print(f\"Recall (Weighted): {recall:.4f}\")\n",
    "    print(f\"F1-Score (Weighted): {f1:.4f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "\n",
    "def evaluate_bounding_boxes(model, dataloader, device, iou_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Evaluate bounding box predictions on the validation set.\n",
    "    \n",
    "    Args:\n",
    "        model (nn.Module): Trained model.\n",
    "        dataloader (DataLoader): Validation DataLoader.\n",
    "        device (torch.device): Device to perform computations on.\n",
    "        iou_threshold (float): Threshold to consider a prediction as correct.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_iou = []\n",
    "    matched = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, targets in tqdm(dataloader, desc=\"Validation Bounding Boxes\", leave=False):\n",
    "            if images is None or targets is None:\n",
    "                continue\n",
    "\n",
    "            images = images.to(device, non_blocking=True)\n",
    "            true_bboxes = targets['boxes'].to(device, non_blocking=True)\n",
    "\n",
    "            with autocast():\n",
    "                pred_bboxes, _ = model(images)\n",
    "\n",
    "            pred_bboxes = pred_bboxes.cpu().numpy()\n",
    "            true_bboxes = true_bboxes.cpu().numpy()\n",
    "\n",
    "            for pred_box, true_box in zip(pred_bboxes, true_bboxes):\n",
    "                iou = calculate_iou(pred_box, true_box)\n",
    "                all_iou.append(iou)\n",
    "                if iou >= iou_threshold:\n",
    "                    matched += 1\n",
    "                total += 1\n",
    "\n",
    "    mean_iou = np.mean(all_iou) if all_iou else 0\n",
    "    precision_at_iou = matched / total if total > 0 else 0\n",
    "\n",
    "    print(\"\\n--- Bounding Box Evaluation ---\")\n",
    "    print(f\"Mean IoU: {mean_iou:.4f}\")\n",
    "    print(f\"Precision at IoU >= {iou_threshold}: {precision_at_iou:.4f}\")\n",
    "\n",
    "def visualize_predictions(model, dataloader, device, label_encoder, num_samples=5):\n",
    "    \"\"\"\n",
    "    Visualize model predictions on a subset of the validation set.\n",
    "    \n",
    "    Args:\n",
    "        model (nn.Module): Trained model.\n",
    "        dataloader (DataLoader): Validation DataLoader.\n",
    "        device (torch.device): Device to perform computations on.\n",
    "        label_encoder (LabelEncoder): Label encoder to decode class labels.\n",
    "        num_samples (int): Number of samples to visualize.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    samples_visualized = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, targets in dataloader:\n",
    "            if images is None or targets is None:\n",
    "                continue\n",
    "\n",
    "            images = images.to(device, non_blocking=True)\n",
    "            true_bboxes = targets['boxes'].to(device, non_blocking=True)\n",
    "            true_labels = targets['labels'].to(device, non_blocking=True)\n",
    "\n",
    "            with autocast():\n",
    "                pred_bboxes, pred_labels = model(images)\n",
    "                preds = torch.argmax(pred_labels, dim=1)\n",
    "\n",
    "            images = images.cpu().numpy()\n",
    "            true_bboxes = true_bboxes.cpu().numpy()\n",
    "            preds = preds.cpu().numpy()\n",
    "            pred_bboxes = pred_bboxes.cpu().numpy()\n",
    "\n",
    "            for img, true_box, true_label, pred_box, pred_label in zip(\n",
    "                images, true_bboxes, true_labels, pred_bboxes, preds\n",
    "            ):\n",
    "                if samples_visualized >= num_samples:\n",
    "                    return\n",
    "\n",
    "                fig, ax = plt.subplots(1)\n",
    "                img = np.transpose(img, (1, 2, 0))  \n",
    "                img = img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
    "                img = np.clip(img, 0, 1)\n",
    "                ax.imshow(img)\n",
    "\n",
    "                # Ground Truth Bounding Box\n",
    "                gt_xmin, gt_ymin, gt_xmax, gt_ymax = true_box\n",
    "                gt_width = gt_xmax - gt_xmin\n",
    "                gt_height = gt_ymax - gt_ymin\n",
    "                gt_rect = patches.Rectangle(\n",
    "                    (gt_xmin, gt_ymin), gt_width, gt_height, \n",
    "                    linewidth=2, edgecolor='g', facecolor='none', label='Ground Truth'\n",
    "                )\n",
    "                ax.add_patch(gt_rect)\n",
    "\n",
    "                # Predicted Bounding Box\n",
    "                pred_xmin, pred_ymin, pred_xmax, pred_ymax = pred_box\n",
    "                pred_width = pred_xmax - pred_xmin\n",
    "                pred_height = pred_ymax - pred_ymin\n",
    "                pred_rect = patches.Rectangle(\n",
    "                    (pred_xmin, pred_ymin), pred_width, pred_height, \n",
    "                    linewidth=2, edgecolor='r', facecolor='none', label='Prediction'\n",
    "                )\n",
    "                ax.add_patch(pred_rect)\n",
    "\n",
    "                # Add Labels\n",
    "                gt_class = label_encoder.inverse_transform([true_label])[0]\n",
    "                pred_class = label_encoder.inverse_transform([pred_label])[0]\n",
    "                plt.title(f\"GT: {gt_class} | Pred: {pred_class}\")\n",
    "\n",
    "                # Create Legend\n",
    "                handles = [\n",
    "                    patches.Patch(color='g', label='Ground Truth'),\n",
    "                    patches.Patch(color='r', label='Prediction')\n",
    "                ]\n",
    "                plt.legend(handles=handles)\n",
    "\n",
    "                plt.show()\n",
    "\n",
    "                samples_visualized += 1\n",
    "\n",
    "def validate_dataset(dataset, num_samples=10):\n",
    "    \"\"\"\n",
    "    Validate the dataset by fetching and printing sample data.\n",
    "    \n",
    "    Args:\n",
    "        dataset (Dataset): PyTorch Dataset to validate.\n",
    "        num_samples (int): Number of samples to validate.\n",
    "    \"\"\"\n",
    "    print(f\"Validating the first {num_samples} samples of the dataset...\")\n",
    "    for i in range(min(num_samples, len(dataset))):\n",
    "        try:\n",
    "            image, targets = dataset[i]\n",
    "            print(f\"Sample {i + 1}:\")\n",
    "            print(f\"  Image shape: {image.shape}\")\n",
    "            print(f\"  BBox: {targets['boxes']}\")\n",
    "            print(f\"  Label: {targets['labels']}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error in sample {i + 1}: {e}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Main Function\n",
    "# -----------------------------\n",
    "\n",
    "def main():\n",
    "    # -----------------------------\n",
    "    # 1. Setup and Configuration\n",
    "    # -----------------------------\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    train_csv_path = 'Train.csv'  \n",
    "    images_dir = 'datasets/dataset/images/compressed/train'  \n",
    "    cached_dir = 'cached_images'  # Directory to store cached tensors\n",
    "    os.makedirs(cached_dir, exist_ok=True)\n",
    "\n",
    "    # -----------------------------\n",
    "    # 2. Data Preparation\n",
    "    # -----------------------------\n",
    "\n",
    "    # Load train data\n",
    "    train = pd.read_csv(train_csv_path)\n",
    "\n",
    "    # Encode class labels into numerical format using LabelEncoder\n",
    "    label_encoder = LabelEncoder()\n",
    "    train['class'] = label_encoder.fit_transform(train['class'])\n",
    "\n",
    "    # Check for missing or corrupted images\n",
    "    missing_images = []\n",
    "    for img_id in train['Image_ID']:\n",
    "        image_path = os.path.join(images_dir, img_id)\n",
    "        if not os.path.exists(image_path):\n",
    "            missing_images.append(img_id)\n",
    "        else:\n",
    "            try:\n",
    "                img = Image.open(image_path)\n",
    "                img.verify()  # Verify that it's an image\n",
    "            except Exception:\n",
    "                missing_images.append(img_id)\n",
    "\n",
    "    if missing_images:\n",
    "        print(f\"Found {len(missing_images)} missing or corrupted images. Removing them from the dataset.\")\n",
    "        train = train[~train['Image_ID'].isin(missing_images)].reset_index(drop=True)\n",
    "    else:\n",
    "        print(\"All images are present and valid.\")\n",
    "\n",
    "    print(f\"Number of training samples after filtering: {len(train)}\")\n",
    "\n",
    "    # Split data into training and validation sets (80% train, 20% val)\n",
    "    train_df, val_df = train_test_split(\n",
    "        train, \n",
    "        test_size=0.2, \n",
    "        random_state=42, \n",
    "        stratify=train['class']\n",
    "    )\n",
    "\n",
    "    print(f\"Training samples: {len(train_df)}, Validation samples: {len(val_df)}\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # 3. Dataset and DataLoader\n",
    "    # -----------------------------\n",
    "\n",
    "    # Preprocess and cache images\n",
    "    cache_images(train_df, images_dir, cached_dir, transform=transforms.Compose([\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],  \n",
    "                             std=[0.229, 0.224, 0.225])   \n",
    "    ]))\n",
    "    cache_images(val_df, images_dir, cached_dir, transform=transforms.Compose([\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],  \n",
    "                             std=[0.229, 0.224, 0.225])   \n",
    "    ]))\n",
    "\n",
    "    # Define original image size\n",
    "    original_image_size = (2560, 1440)  # Replace with your actual image size\n",
    "    resized_image_size = (128, 128)\n",
    "\n",
    "    # Instantiate Cached Datasets\n",
    "    train_dataset = CachedDataset(dataframe=train_df, cached_dir=cached_dir, \n",
    "                                  original_image_size=original_image_size, \n",
    "                                  resized_image_size=resized_image_size)\n",
    "    val_dataset = CachedDataset(dataframe=val_df, cached_dir=cached_dir, \n",
    "                                original_image_size=original_image_size, \n",
    "                                resized_image_size=resized_image_size)\n",
    "\n",
    "    # Validate Datasets\n",
    "    validate_dataset(train_dataset)\n",
    "    validate_dataset(val_dataset)\n",
    "\n",
    "    # Determine optimal number of workers\n",
    "    num_workers = 0  # Set to 0 for initial debugging\n",
    "    print(f\"Using {num_workers} workers for DataLoader.\")\n",
    "\n",
    "    # Determine prefetch_factor based on num_workers\n",
    "    prefetch_factor = 2 if num_workers > 0 else None\n",
    "\n",
    "    # Instantiate DataLoaders with conditional prefetch_factor\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=128,          \n",
    "        shuffle=True,           \n",
    "        num_workers=num_workers,  \n",
    "        pin_memory=False,\n",
    "        persistent_workers=False,\n",
    "        prefetch_factor=prefetch_factor\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, \n",
    "        batch_size=128,          \n",
    "        shuffle=False,          \n",
    "        num_workers=num_workers,  \n",
    "        pin_memory=False,\n",
    "        persistent_workers=False,\n",
    "        prefetch_factor=prefetch_factor\n",
    "    )\n",
    "\n",
    "    # -----------------------------\n",
    "    # 4. Model Definition\n",
    "    # -----------------------------\n",
    "\n",
    "    num_classes = len(train['class'].unique())\n",
    "\n",
    "    model = CustomCNN(num_classes=num_classes).to(device)\n",
    "\n",
    "    # Print the model structure (optional)\n",
    "    print(f\"Custom CNN Model:\\n{model}\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # 5. Training Loop with Optimizations\n",
    "    # -----------------------------\n",
    "\n",
    "    # Define loss functions\n",
    "    class IoULoss(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(IoULoss, self).__init__()\n",
    "\n",
    "        def forward(self, pred_boxes, target_boxes):\n",
    "            # Remove sigmoid if bounding boxes are scaled to image dimensions\n",
    "            # pred_boxes = torch.sigmoid(pred_boxes)\n",
    "            # target_boxes = torch.sigmoid(target_boxes)\n",
    "            \n",
    "            # Calculate Intersection coordinates\n",
    "            x1 = torch.max(pred_boxes[:, 0], target_boxes[:, 0])\n",
    "            y1 = torch.max(pred_boxes[:, 1], target_boxes[:, 1])\n",
    "            x2 = torch.min(pred_boxes[:, 2], target_boxes[:, 2])\n",
    "            y2 = torch.min(pred_boxes[:, 3], target_boxes[:, 3])\n",
    "            \n",
    "            # Calculate Intersection area\n",
    "            intersection = (x2 - x1).clamp(min=0) * (y2 - y1).clamp(min=0)\n",
    "            \n",
    "            # Calculate areas\n",
    "            pred_area = (pred_boxes[:, 2] - pred_boxes[:, 0]).clamp(min=0) * \\\n",
    "                        (pred_boxes[:, 3] - pred_boxes[:, 1]).clamp(min=0)\n",
    "            target_area = (target_boxes[:, 2] - target_boxes[:, 0]).clamp(min=0) * \\\n",
    "                          (target_boxes[:, 3] - target_boxes[:, 1]).clamp(min=0)\n",
    "            \n",
    "            # Calculate Union area\n",
    "            union = pred_area + target_area - intersection + 1e-6  # Avoid division by zero\n",
    "            \n",
    "            # Calculate IoU\n",
    "            iou = intersection / union\n",
    "            \n",
    "            # Calculate IoU Loss\n",
    "            loss = 1 - iou\n",
    "            return loss.mean()\n",
    "\n",
    "    iou_loss_fn = IoULoss()\n",
    "    class_loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Define optimizer and scheduler\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "\n",
    "    # Initialize GradScaler for mixed precision\n",
    "    scaler = GradScaler()\n",
    "\n",
    "    # Define number of epochs\n",
    "    num_epochs = 10  # Adjust as needed\n",
    "\n",
    "    # Training loop with validation and checkpointing\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\n=== Epoch {epoch + 1}/{num_epochs} ===\")\n",
    "        model.train()\n",
    "        total_iou_loss, total_class_loss = 0.0, 0.0\n",
    "        train_loader_iter = tqdm(train_loader, desc=\"Training\", leave=False)\n",
    "\n",
    "        for batch_idx, (images, targets) in enumerate(train_loader_iter):\n",
    "            if images is None or targets is None:\n",
    "                print(f\"Skipping batch {batch_idx + 1} due to None values.\")\n",
    "                continue\n",
    "\n",
    "            # Debug statement to trace batch processing\n",
    "            # print(f\"Processing batch {batch_idx + 1}/{len(train_loader)}\")\n",
    "\n",
    "            images = images.to(device, non_blocking=True)\n",
    "            bboxes = targets['boxes'].to(device, non_blocking=True)\n",
    "            labels = targets['labels'].to(device, non_blocking=True)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            with autocast():\n",
    "                pred_bboxes, pred_labels = model(images)\n",
    "                bbox_loss = iou_loss_fn(pred_bboxes, bboxes)\n",
    "                class_loss = class_loss_fn(pred_labels, labels)\n",
    "                total_loss = bbox_loss + class_loss\n",
    "            \n",
    "            scaler.scale(total_loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            total_iou_loss += bbox_loss.item()\n",
    "            total_class_loss += class_loss.item()\n",
    "\n",
    "            # Log every 10 batches\n",
    "            if (batch_idx + 1) % 10 == 0:\n",
    "                print(f\"Batch {batch_idx + 1}/{len(train_loader)} - IoU Loss: {bbox_loss.item():.4f}, Class Loss: {class_loss.item():.4f}\")\n",
    "\n",
    "            train_loader_iter.set_postfix({'IoU Loss': bbox_loss.item(), 'Class Loss': class_loss.item()})\n",
    "\n",
    "        avg_iou_loss = total_iou_loss / len(train_loader)\n",
    "        avg_class_loss = total_class_loss / len(train_loader)\n",
    "        print(f\"Training Losses -> IoU Loss: {avg_iou_loss:.4f}, Class Loss: {avg_class_loss:.4f}\")\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        # -----------------------------\n",
    "        # 6. Validation After Each Epoch\n",
    "        # -----------------------------\n",
    "\n",
    "        print(f\"\\n=== Validation After Epoch {epoch + 1} ===\")\n",
    "        evaluate_classification(model, val_loader, device)\n",
    "        evaluate_bounding_boxes(model, val_loader, device, iou_threshold=0.5)\n",
    "\n",
    "        # -----------------------------\n",
    "        # 7. Save the Trained Model\n",
    "        # -----------------------------\n",
    "\n",
    "        checkpoint_path = f'custom_cnn_model_epoch_{epoch + 1}.pth'\n",
    "        torch.save(model.state_dict(), checkpoint_path)\n",
    "        print(f\"Checkpoint saved to '{checkpoint_path}'\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # 8. Visualization of Predictions (Optional)\n",
    "    # -----------------------------\n",
    "\n",
    "    print(\"\\n=== Visualizing Predictions on Validation Set ===\")\n",
    "    visualize_predictions(model, val_loader, device, label_encoder, num_samples=5)\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Entry Point\n",
    "# -----------------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
